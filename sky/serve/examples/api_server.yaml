resources:
  accelerators: A100:1
  cloud: gcp
  # region: us-central1
  # use_spot: True
  image_id: projects/skypilot-375900/global/images/fastchat-serve-v0
  
num_nodes: 1

file_mounts:
  ~/chatlogs:
    name: skypilot-chatbot-logs
    store: gcs
    mode: MOUNT

service:
  port: 8081
  readiness_probe: /health/v1/models

setup: |
  conda activate chatbot
  if [ $? -eq 0 ]; then
    echo 'conda env exists'
  else
    # Setup the environment
    conda create -n chatbot python=3.10 -y
    conda activate chatbot
    pip3 install fschat
  fi

run: |
  conda activate chatbot
  python3 -m fastchat.serve.controller --host 0.0.0.0 --port 21001 > ~/controller.log 2>&1 &

  WORKER_IP=$(hostname -I | cut -d' ' -f1)
  CONTROLLER_PORT=21001
  WORKER_PORT=21002
  # python3 -m fastchat.serve.model_worker \
  #   --model-path lmsys/vicuna-7b-v1.3 \
  #   --controller-address http://${WORKER_IP}:${CONTROLLER_PORT} \
  #   --worker-address http://${WORKER_IP}:${WORKER_PORT} \
  #   --host 0.0.0.0 \
  #   --port ${WORKER_PORT} > ~/worker.log 2>&1 &

  cd FastChat
  python3 -m fastchat.serve.vllm_worker \
    --model-path lmsys/vicuna-7b-v1.3 \
    --controller-address http://${WORKER_IP}:${CONTROLLER_PORT} \
    --worker-address http://${WORKER_IP}:${WORKER_PORT} \
    --host 0.0.0.0 \
    --port ${WORKER_PORT} \
    --tokenizer hf-internal-testing/llama-tokenizer > ~/worker.log 2>&1 &


  HOST_IP=$(hostname -I | cut -d' ' -f1)
  python3 -m fastchat.serve.openai_api_server --host ${HOST_IP} --port 8081
